{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lxiXC9sN8m-",
        "outputId": "801af12b-c921-43dd-8df5-d5ee43a9f094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATASET_PATH = '/content/drive/MyDrive/cvpr_final'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "deleted_count = 0\n",
        "for subdir, dirs, files in os.walk(DATASET_PATH):\n",
        "    for file in files:\n",
        "        filepath = os.path.join(subdir, file)\n",
        "        try:\n",
        "            img = Image.open(filepath)\n",
        "            img.verify()\n",
        "        except:\n",
        "            os.remove(filepath)\n",
        "            deleted_count += 1\n",
        "\n",
        "print(f\"Cleaned up {deleted_count} bad files from local storage.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWhwQrG1WosM",
        "outputId": "fd0fa3b1-7d12-4797-d6c3-541600033665"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned up 2 bad files from local storage.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "MAX_PHOTOS = 25\n",
        "\n",
        "def balance_dataset(path, limit):\n",
        "    print(f\"Scanning: {path}\")\n",
        "    subfolders = [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]\n",
        "\n",
        "    for folder in subfolders:\n",
        "        folder_path = os.path.join(path, folder)\n",
        "        images = [img for img in os.listdir(folder_path) if img.lower().endswith(('.png', '.jpg', '.jpeg','.jfif'))]\n",
        "\n",
        "        current_count = len(images)\n",
        "        print(f\"Folder [{folder}]: {current_count} images\")\n",
        "\n",
        "        if current_count > limit:\n",
        "            diff = current_count - limit\n",
        "            to_delete = random.sample(images, k=diff)\n",
        "\n",
        "            for img_name in to_delete:\n",
        "                os.remove(os.path.join(folder_path, img_name))\n",
        "\n",
        "            print(f\"Trimmed {diff} images. New count: {limit}\")\n",
        "        elif current_count < limit:\n",
        "            print(f\"Below limit. Keeping all {current_count} images.\")\n",
        "        else:\n",
        "            print(f\"balanced\")\n",
        "\n",
        "    print(\"\\nDataset balancing complete\")\n",
        "\n",
        "balance_dataset(DATASET_PATH, MAX_PHOTOS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFr_QZCYxucu",
        "outputId": "c8a3aae9-b547-42a2-c1f2-345c1534002f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning: /content/drive/MyDrive/cvpr_final\n",
            "Folder [22-48133-2 ]: 21 images\n",
            "Below limit. Keeping all 21 images.\n",
            "Folder [22-48005-2]: 23 images\n",
            "Below limit. Keeping all 23 images.\n",
            "Folder [22-46887-1]: 17 images\n",
            "Below limit. Keeping all 17 images.\n",
            "Folder [22-48725-3]: 0 images\n",
            "Below limit. Keeping all 0 images.\n",
            "Folder [22-49355-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-46590-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49331-3]: 0 images\n",
            "Below limit. Keeping all 0 images.\n",
            "Folder [22-48682-3]: 0 images\n",
            "Below limit. Keeping all 0 images.\n",
            "Folder [22-48666-3]: 0 images\n",
            "Below limit. Keeping all 0 images.\n",
            "Folder [22-46983-1]: 18 images\n",
            "Below limit. Keeping all 18 images.\n",
            "Folder [22-48091-2]: 21 images\n",
            "Below limit. Keeping all 21 images.\n",
            "Folder [23-51308-1]: 8 images\n",
            "Below limit. Keeping all 8 images.\n",
            "Folder [22-48833-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-48915-3]: 0 images\n",
            "Below limit. Keeping all 0 images.\n",
            "Folder [21-45902-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49068-3]: 0 images\n",
            "Below limit. Keeping all 0 images.\n",
            "Folder [22-48841-3]: 0 images\n",
            "Below limit. Keeping all 0 images.\n",
            "Folder [22-48582-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49783-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49791-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49843-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49824-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-46138-1]: 21 images\n",
            "Below limit. Keeping all 21 images.\n",
            "Folder [22-48569-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-48021-2]: 19 images\n",
            "Below limit. Keeping all 19 images.\n",
            "Folder [22-49862-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49643-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-46536-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-47898-2]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-48205-2]: 23 images\n",
            "Below limit. Keeping all 23 images.\n",
            "Folder [22-46342-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [23-51127-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-47892-2]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49507-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-47884-2]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-46258-1]: 15 images\n",
            "Below limit. Keeping all 15 images.\n",
            "Folder [23-50346-1]: 60 images\n",
            "Trimmed 35 images. New count: 25\n",
            "Folder [22-48023-2 ]: 13 images\n",
            "Below limit. Keeping all 13 images.\n",
            "Folder [22-47542-2]: 0 images\n",
            "Below limit. Keeping all 0 images.\n",
            "Folder [22-49575-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [23-50277-1]: 14 images\n",
            "Below limit. Keeping all 14 images.\n",
            "Folder [22-49037-3]: 19 images\n",
            "Below limit. Keeping all 19 images.\n",
            "Folder [22-46139-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49196-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [23-50254-1]: 17 images\n",
            "Below limit. Keeping all 17 images.\n",
            "Folder [22-47813-2]: 19 images\n",
            "Below limit. Keeping all 19 images.\n",
            "Folder [22-49338-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-47968-2]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49451-3]: 21 images\n",
            "Below limit. Keeping all 21 images.\n",
            "Folder [23-50066-1]: 28 images\n",
            "Trimmed 3 images. New count: 25\n",
            "Folder [22-49852-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49370-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49421-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-48310-3]: 0 images\n",
            "Below limit. Keeping all 0 images.\n",
            "Folder [22-49609-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-46275-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [23-50158-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-48055-2]: 27 images\n",
            "Trimmed 2 images. New count: 25\n",
            "Folder [22-46666-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49800-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [23-53577-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-46293-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49745-3]: 21 images\n",
            "Below limit. Keeping all 21 images.\n",
            "Folder [22-46473-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49167-3]: 23 images\n",
            "Below limit. Keeping all 23 images.\n",
            "Folder [22-48064-2]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-46141-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49453-3]: 25 images\n",
            "balanced\n",
            "Folder [22-49450-3]: 8 images\n",
            "Below limit. Keeping all 8 images.\n",
            "Folder [22-46679-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-46931-1]: 15 images\n",
            "Below limit. Keeping all 15 images.\n",
            "Folder [22-48434-3]: 37 images\n",
            "Trimmed 12 images. New count: 25\n",
            "Folder [22-47180-1 ]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49861-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-48541-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [23-50279-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-46156-1]: 18 images\n",
            "Below limit. Keeping all 18 images.\n",
            "Folder [22-47384-2]: 15 images\n",
            "Below limit. Keeping all 15 images.\n",
            "Folder [22-47925-2]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-47894-2]: 21 images\n",
            "Below limit. Keeping all 21 images.\n",
            "Folder [22-46945-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-47402-2]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-46877-1 (1)]: 0 images\n",
            "Below limit. Keeping all 0 images.\n",
            "Folder [22-46877-1]: 19 images\n",
            "Below limit. Keeping all 19 images.\n",
            "Folder [22-48039-2]: 16 images\n",
            "Below limit. Keeping all 16 images.\n",
            "Folder [22-47294-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-47027-1]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49644-3]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-49621-3]: 59 images\n",
            "Trimmed 34 images. New count: 25\n",
            "Folder [22-47966-2]: 24 images\n",
            "Below limit. Keeping all 24 images.\n",
            "Folder [22-49619-3]: 100 images\n",
            "Trimmed 75 images. New count: 25\n",
            "Folder [22-46586-1]: 0 images\n",
            "Below limit. Keeping all 0 images.\n",
            "Folder [22-49440-3]: 0 images\n",
            "Below limit. Keeping all 0 images.\n",
            "Folder [23-50689-1]: 9 images\n",
            "Below limit. Keeping all 9 images.\n",
            "Folder [22-47934-2]: 20 images\n",
            "Below limit. Keeping all 20 images.\n",
            "Folder [22-46840-1]: 21 images\n",
            "Below limit. Keeping all 21 images.\n",
            "Folder [22-46677-1]: 39 images\n",
            "Trimmed 14 images. New count: 25\n",
            "\n",
            "Dataset balancing complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBM3XrAbOxL4",
        "outputId": "57566d94-5ba2-4d5a-e936-cbff66dd4a4b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1344 images belonging to 97 classes.\n",
            "Found 319 images belonging to 97 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50\n",
        ")\n",
        "\n",
        "model.save('student_recognition_model.h5')\n",
        "print(\"Training done. Model saved as 'student_recognition_model.h5'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpYHbFb_Oyn8",
        "outputId": "ba9cb1e8-cbc5-4bae-9448-33c5ac2ce3f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 14s/step - accuracy: 0.0143 - loss: 4.5842 - val_accuracy: 0.0125 - val_loss: 4.4873\n",
            "Epoch 2/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 4s/step - accuracy: 0.0183 - loss: 4.4816 - val_accuracy: 0.0345 - val_loss: 4.3865\n",
            "Epoch 3/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.0270 - loss: 4.3693 - val_accuracy: 0.0784 - val_loss: 4.0567\n",
            "Epoch 4/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - accuracy: 0.0512 - loss: 4.1086 - val_accuracy: 0.1003 - val_loss: 3.7529\n",
            "Epoch 5/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 4s/step - accuracy: 0.0774 - loss: 3.8626 - val_accuracy: 0.1442 - val_loss: 3.5937\n",
            "Epoch 6/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - accuracy: 0.1079 - loss: 3.7138 - val_accuracy: 0.2163 - val_loss: 3.4236\n",
            "Epoch 7/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.1361 - loss: 3.5132 - val_accuracy: 0.2665 - val_loss: 3.1147\n",
            "Epoch 8/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.1726 - loss: 3.3427 - val_accuracy: 0.2539 - val_loss: 3.0797\n",
            "Epoch 9/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.1921 - loss: 3.2606 - val_accuracy: 0.3103 - val_loss: 2.8735\n",
            "Epoch 10/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 4s/step - accuracy: 0.2377 - loss: 3.0170 - val_accuracy: 0.3197 - val_loss: 2.8767\n",
            "Epoch 11/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 4s/step - accuracy: 0.2856 - loss: 2.9394 - val_accuracy: 0.3135 - val_loss: 2.7197\n",
            "Epoch 12/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4s/step - accuracy: 0.2656 - loss: 2.8868 - val_accuracy: 0.3699 - val_loss: 2.5656\n",
            "Epoch 13/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 4s/step - accuracy: 0.2869 - loss: 2.8271 - val_accuracy: 0.4263 - val_loss: 2.3975\n",
            "Epoch 14/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 4s/step - accuracy: 0.3322 - loss: 2.6430 - val_accuracy: 0.4702 - val_loss: 2.2349\n",
            "Epoch 15/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4s/step - accuracy: 0.3447 - loss: 2.5537 - val_accuracy: 0.4796 - val_loss: 2.2442\n",
            "Epoch 16/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - accuracy: 0.3538 - loss: 2.4745 - val_accuracy: 0.5392 - val_loss: 2.0506\n",
            "Epoch 17/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 4s/step - accuracy: 0.3974 - loss: 2.2729 - val_accuracy: 0.5078 - val_loss: 2.1116\n",
            "Epoch 18/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 4s/step - accuracy: 0.3979 - loss: 2.3448 - val_accuracy: 0.5235 - val_loss: 1.9333\n",
            "Epoch 19/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.4398 - loss: 2.0883 - val_accuracy: 0.5455 - val_loss: 1.8635\n",
            "Epoch 20/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 5s/step - accuracy: 0.4590 - loss: 2.0130 - val_accuracy: 0.5674 - val_loss: 1.7991\n",
            "Epoch 21/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.4748 - loss: 2.0612 - val_accuracy: 0.5517 - val_loss: 1.7364\n",
            "Epoch 22/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 5s/step - accuracy: 0.4981 - loss: 1.8900 - val_accuracy: 0.5799 - val_loss: 1.7053\n",
            "Epoch 23/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.5212 - loss: 1.8464 - val_accuracy: 0.5987 - val_loss: 1.6389\n",
            "Epoch 24/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 5s/step - accuracy: 0.5130 - loss: 1.8017 - val_accuracy: 0.6176 - val_loss: 1.6152\n",
            "Epoch 25/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - accuracy: 0.5206 - loss: 1.7803 - val_accuracy: 0.6050 - val_loss: 1.5258\n",
            "Epoch 26/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 4s/step - accuracy: 0.5592 - loss: 1.6127 - val_accuracy: 0.6207 - val_loss: 1.6168\n",
            "Epoch 27/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.5842 - loss: 1.5318 - val_accuracy: 0.6364 - val_loss: 1.5665\n",
            "Epoch 28/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 5s/step - accuracy: 0.5622 - loss: 1.5764 - val_accuracy: 0.6176 - val_loss: 1.4147\n",
            "Epoch 29/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 4s/step - accuracy: 0.5871 - loss: 1.5032 - val_accuracy: 0.6144 - val_loss: 1.5414\n",
            "Epoch 30/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 4s/step - accuracy: 0.5832 - loss: 1.5416 - val_accuracy: 0.6552 - val_loss: 1.3304\n",
            "Epoch 31/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4s/step - accuracy: 0.6023 - loss: 1.4436 - val_accuracy: 0.6270 - val_loss: 1.4817\n",
            "Epoch 32/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 4s/step - accuracy: 0.6174 - loss: 1.3790 - val_accuracy: 0.6614 - val_loss: 1.3184\n",
            "Epoch 33/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.6255 - loss: 1.3355 - val_accuracy: 0.6614 - val_loss: 1.3319\n",
            "Epoch 34/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4s/step - accuracy: 0.6408 - loss: 1.2861 - val_accuracy: 0.6552 - val_loss: 1.2075\n",
            "Epoch 35/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.6488 - loss: 1.3120 - val_accuracy: 0.6395 - val_loss: 1.3936\n",
            "Epoch 36/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.6606 - loss: 1.2194 - val_accuracy: 0.6928 - val_loss: 1.2118\n",
            "Epoch 37/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.6574 - loss: 1.1937 - val_accuracy: 0.6426 - val_loss: 1.3293\n",
            "Epoch 38/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 4s/step - accuracy: 0.6319 - loss: 1.2872 - val_accuracy: 0.6865 - val_loss: 1.1866\n",
            "Epoch 39/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - accuracy: 0.6578 - loss: 1.2027 - val_accuracy: 0.6583 - val_loss: 1.1521\n",
            "Epoch 40/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 4s/step - accuracy: 0.6905 - loss: 1.0776 - val_accuracy: 0.7022 - val_loss: 1.1832\n",
            "Epoch 41/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 5s/step - accuracy: 0.6516 - loss: 1.2070 - val_accuracy: 0.7147 - val_loss: 1.0966\n",
            "Epoch 42/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.6907 - loss: 1.1243 - val_accuracy: 0.6614 - val_loss: 1.2351\n",
            "Epoch 43/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 5s/step - accuracy: 0.6460 - loss: 1.1536 - val_accuracy: 0.6834 - val_loss: 1.2068\n",
            "Epoch 44/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 4s/step - accuracy: 0.6916 - loss: 1.0395 - val_accuracy: 0.7179 - val_loss: 1.1799\n",
            "Epoch 45/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - accuracy: 0.7084 - loss: 1.0274 - val_accuracy: 0.7085 - val_loss: 1.1507\n",
            "Epoch 46/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - accuracy: 0.7093 - loss: 0.9625 - val_accuracy: 0.7085 - val_loss: 1.1267\n",
            "Epoch 47/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.6946 - loss: 1.0083 - val_accuracy: 0.6771 - val_loss: 1.2492\n",
            "Epoch 48/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.7179 - loss: 1.0208 - val_accuracy: 0.7022 - val_loss: 1.1180\n",
            "Epoch 49/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 4s/step - accuracy: 0.7044 - loss: 1.0667 - val_accuracy: 0.6708 - val_loss: 1.1288\n",
            "Epoch 50/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 4s/step - accuracy: 0.6866 - loss: 1.0803 - val_accuracy: 0.7210 - val_loss: 1.1014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training done. Model saved as 'student_recognition_model.h5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(train_generator.class_indices.keys())\n",
        "with open(\"labels.txt\", \"w\") as f:\n",
        "    f.write(\"\\n\".join(labels))"
      ],
      "metadata": {
        "id": "P_uB1ccOO3aN"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}